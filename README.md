# ReXcan - Intelligent Invoice Processing System

**ReXcan** is an AI-driven intelligent invoice processing system that automatically extracts, validates, and standardizes invoice data from any format, regardless of vendor template variations. The system combines advanced OCR, NLP/LLM capabilities, and business rule validation to deliver accurate, structured invoice data while maintaining a human-in-the-loop review process for quality assurance.

## ğŸ¯ Problem Statement

### The Challenge

In almost every company, the Accounts Payable (AP) department faces a critical operational bottleneck: manually processing thousands of invoices that arrive in inconsistent digital formats. These invoices come from various vendors as text-based PDFs, scanned documents, email bodies, and other unstructured formats.

### Current Pain Points

- **Manual Labor Intensive**: Human employees must read each document individually, manually identify key details (invoice number, vendor name, amount due, due date, line items), and re-enter data into accounting systems
- **Error-Prone Process**: Manual data entry leads to mistakes, duplicate payments, incorrect payments, and late fees
- **Scalability Issues**: Each vendor uses a different invoice template, making rule-based systems unreliable. As companies grow, the manual processing burden becomes unsustainable
- **Inconsistent Data Formats**: Dates, currencies, and vendor names appear in various formats, making downstream integration and analytics difficult

### What We're Solving

ReXcan addresses these challenges by providing an intelligent automation pipeline that can:

- **Ingest** invoices from multiple sources and formats (text PDFs, scanned documents, emails)
- **Understand** invoice content contextually using AI/NLP capabilities
- **Extract** key financial data accurately, including:
  - Invoice ID/Number
  - Vendor Name
  - Invoice Date & Due Date
  - Total Amount, Tax, Subtotal
  - Line Items
  - Currency Information
- **Standardize** extracted data into consistent formats (canonicalization)
- **Flag** low-confidence extractions for human verification
- **Output** structured data (JSON/CSV) compatible with accounting systems

### Expected Impact

- **Cost Reduction**: Automates thousands of manual data entry hours, reducing processing costs by 60-80%
- **Increased Accuracy**: Prevents data entry mistakes, eliminates duplicate payments, reduces incorrect payments
- **Faster Processing**: Processes invoices in seconds instead of minutes, enabling early payment discounts
- **Improved Compliance**: Maintains complete digital audit trail, ensures transparency and regulatory compliance
- **Consistent Data Quality**: Canonicalization ensures all extracted information follows uniform standards

---

## ğŸ—ï¸ System Architecture

ReXcan follows a **three-tier microservices architecture**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend Layer                            â”‚
â”‚              React + TypeScript + Tailwind CSS               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  â€¢ Document Upload & Management                       â”‚   â”‚
â”‚  â”‚  â€¢ Real-time Processing Status                        â”‚   â”‚
â”‚  â”‚  â€¢ Review Queue & Manual Corrections                  â”‚   â”‚
â”‚  â”‚  â€¢ Metrics Dashboard                                  â”‚   â”‚
â”‚  â”‚  â€¢ Export Interface (CSV/JSON)                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ HTTP/REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Node.js/Express Backend (Port 3000)             â”‚
â”‚              TypeScript + MongoDB + Redis                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  â€¢ User Authentication & Authorization                â”‚   â”‚
â”‚  â”‚  â€¢ Document Management (MongoDB)                       â”‚   â”‚
â”‚  â”‚  â€¢ Job Queue Management (Redis)                       â”‚   â”‚
â”‚  â”‚  â€¢ Background Workers                                  â”‚   â”‚
â”‚  â”‚  â€¢ API Gateway to Python Service                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ HTTP/REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Python FastAPI Service (Port 8000)                â”‚
â”‚              Core Invoice Processing Engine                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  â€¢ OCR Pipeline (pdfplumber, EasyOCR, Tesseract)     â”‚   â”‚
â”‚  â”‚  â€¢ Heuristic Field Extraction                         â”‚   â”‚
â”‚  â”‚  â€¢ LLM Fallback (Gemini, Groq, OpenAI, Claude)       â”‚   â”‚
â”‚  â”‚  â€¢ Confidence Scoring                                 â”‚   â”‚
â”‚  â”‚  â€¢ Canonicalization                                   â”‚   â”‚
â”‚  â”‚  â€¢ Validation & Deduplication                          â”‚   â”‚
â”‚  â”‚  â€¢ Audit Trail                                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

**Frontend:**
- React 18 with TypeScript
- Vite for build tooling
- Tailwind CSS for styling
- React Context for state management

**Backend (Node.js):**
- Express.js with TypeScript
- MongoDB with Mongoose
- Redis for job queue
- JWT authentication
- Background workers for async processing

**Backend (Python):**
- FastAPI for REST API
- pdfplumber for text-layer PDF extraction
- EasyOCR + Tesseract for OCR
- Google Cloud Document AI (fallback)
- Multi-provider LLM support (Gemini, Groq, OpenAI, Anthropic)
- RapidFuzz for fuzzy matching
- OpenCV for image preprocessing

---

## ğŸ”„ Processing Pipeline

The invoice processing pipeline follows a **deterministic-first approach** with intelligent LLM fallback:

### Stage 1: Document Upload & Validation
```
User uploads invoice (PDF/image)
    â†“
File validation (size, MIME type, safety checks)
    â†“
File stored in uploads/ directory
    â†“
Job ID generated and stored
```

### Stage 2: Text Extraction (Multi-Layer OCR)
```
1. Primary: pdfplumber (text-layer PDFs)
   - Fast extraction (<1s)
   - 95% confidence for text-based PDFs
   
2. OCR Fallback (if <50 chars extracted)
   a. PDF â†’ Images (150 DPI)
   b. OpenCV preprocessing (grayscale, denoise)
   c. EasyOCR (primary) + Tesseract (fallback)
   d. Merge results (prefer higher confidence)
   
3. Cloud OCR Fallback (if local OCR fails)
   - Google Cloud Document AI
   
4. OCR results cached by file hash
```

### Stage 3: Heuristic Field Extraction
```
For each field (Invoice ID, Date, Amount, Vendor, etc.):
    â†“
1. Label-based extraction (proximity matching)
   - Find labels like "Invoice #", "Date:", "Total:"
   - Extract nearby values
   
2. Regex pattern matching
   - Strict patterns first
   - Relaxed patterns as fallback
   
3. Layout-aware heuristics
   - Top-right region for Invoice ID
   - Bottom 40% for totals
   - Top 20% for vendor name
   
4. Confidence scoring per field
   Formula: 0.2 + 0.7 * min(ocr_c, label_score, regex_score) + (0.1 if llm_agree)
```

### Stage 4: LLM Fallback (Surgical)
```
If confidence < 0.5 OR required field missing:
    â†“
1. Select top K=12 most relevant OCR blocks
   (by confidence + proximity to field location)
   
2. Call LLM with context (priority order):
   - Groq (Llama3 8B) - Fastest, free tier
   - Gemini 1.5 Flash - Fast, free tier
   - OpenAI GPT-4o-mini - Good accuracy
   - Anthropic Claude - Best accuracy
   
3. Validate LLM output with regex
   
4. Cache response by SHA256 of context
```

### Stage 5: Canonicalization
```
Date normalization:
   All formats â†’ YYYY-MM-DD (ISO 8601)
   
Currency normalization:
   $, USD, US$ â†’ USD
   â‚¹, INR â†’ INR
   â‚¬, EUR â†’ EUR
   (ISO 4217 codes)
   
Vendor canonicalization:
   Fuzzy matching (RapidFuzz)
   "Microsoft Corp." â†’ "Microsoft Corporation"
   Creates canonical vendor ID
   
Amount normalization:
   EU format (1.234,56) â†’ US format (1,234.56)
```

### Stage 6: Validation & Quality Checks
```
1. Arithmetic validation
   - Subtotal + Tax = Total (within tolerance)
   
2. Duplicate detection
   - Exact duplicates (SHA256 hash)
   - Near-duplicates (fuzzy matching)
   
3. Field validation
   - Regex validation
   - Type checking
   - Range validation
   
4. Auto-flagging
   - Low confidence fields (<0.85)
   - Arithmetic mismatches
   - Duplicate invoices
```

### Stage 7: Human-in-the-Loop Review
```
Flagged invoices â†’ Review Queue
    â†“
Human reviewer corrects fields
    â†“
Corrections logged in audit trail
    â†“
Learning system captures patterns
    â†“
Vendor aliases & rules updated
```

### Stage 8: Export & Integration
```
Structured data export:
   - JSON format (complete data)
   - CSV format (ERP-friendly)
   - ERP-specific formats:
     â€¢ QuickBooks
     â€¢ SAP
     â€¢ Oracle
     â€¢ Xero
```

---

## ğŸ“ Repository Structure

```
ReXcan/
â”œâ”€â”€ client/                          # Frontend Application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/              # React components (27 files)
â”‚   â”‚   â”‚   â”œâ”€â”€ InvoiceProcessingStatus.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ConfidenceIndicator.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ LineItemsTable.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ReviewQueue.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ MetricsDashboard.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ pages/                   # Page components
â”‚   â”‚   â”œâ”€â”€ services/                # API services
â”‚   â”‚   â”œâ”€â”€ contexts/                # React contexts (Auth)
â”‚   â”‚   â”œâ”€â”€ types/                   # TypeScript types
â”‚   â”‚   â””â”€â”€ config/                  # Configuration
â”‚   â”œâ”€â”€ public/                      # Static assets
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ server/                          # Node.js Backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ controllers/             # Request handlers (5 files)
â”‚   â”‚   â”œâ”€â”€ services/                # Business logic (14 files)
â”‚   â”‚   â”œâ”€â”€ routes/                  # API routes (5 files)
â”‚   â”‚   â”œâ”€â”€ models/                  # Mongoose models (2 files)
â”‚   â”‚   â”œâ”€â”€ middlewares/             # Custom middlewares (8 files)
â”‚   â”‚   â”œâ”€â”€ workers/                 # Background workers (4 files)
â”‚   â”‚   â”œâ”€â”€ config/                  # Configuration (4 files)
â”‚   â”‚   â””â”€â”€ utils/                   # Utilities (3 files)
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ uploads/                 # Uploaded files
â”‚   â”‚   â””â”€â”€ processed/               # Processed files
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ python/                          # Python Processing Engine
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                  # FastAPI application
â”‚   â”‚   â”œâ”€â”€ ocr_engine.py            # OCR wrappers
â”‚   â”‚   â”œâ”€â”€ extract_text.py          # Text extraction pipeline
â”‚   â”‚   â”œâ”€â”€ preprocess.py            # Image preprocessing
â”‚   â”‚   â”œâ”€â”€ heuristics.py            # Field extractors
â”‚   â”‚   â”œâ”€â”€ confidence.py            # Confidence scoring
â”‚   â”‚   â”œâ”€â”€ llm_router.py            # LLM wrapper & caching
â”‚   â”‚   â”œâ”€â”€ canonicalize.py          # Data normalization
â”‚   â”‚   â”œâ”€â”€ validator.py             # Field validation
â”‚   â”‚   â”œâ”€â”€ deduplication.py        # Duplicate detection
â”‚   â”‚   â”œâ”€â”€ line_items.py            # Line item extraction
â”‚   â”‚   â”œâ”€â”€ audit.py                 # Audit logging
â”‚   â”‚   â”œâ”€â”€ safety.py                # Safety checks
â”‚   â”‚   â”œâ”€â”€ learning.py              # Learning from edits
â”‚   â”‚   â””â”€â”€ models.py                # Pydantic models
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ gold/                    # Gold standard samples
â”‚   â”‚   â”œâ”€â”€ vendors.csv              # Canonical vendor list
â”‚   â”‚   â””â”€â”€ outputs/                 # Processed outputs
â”‚   â”œâ”€â”€ cache/                       # OCR & LLM cache
â”‚   â”œâ”€â”€ uploads/                     # Uploaded files
â”‚   â”œâ”€â”€ tests/                       # Unit tests
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ documentation/                   # Project Documentation
â”‚   â”œâ”€â”€ PROBLEM_STATEMENT.md
â”‚   â”œâ”€â”€ IMPLEMENTATION_SUMMARY.md
â”‚   â”œâ”€â”€ FEATURES_LIST.md
â”‚   â””â”€â”€ QUICK_START.md
â”‚
â”œâ”€â”€ start-all.sh                     # Start all services script
â””â”€â”€ README.md                        # This file
```

---

## ğŸš€ Getting Started

### Prerequisites

- **Node.js** (v18 or higher)
- **Python** (3.9 or higher)
- **MongoDB** (local or remote)
- **Redis** (for job queue)
- **System Dependencies**:
  - Tesseract OCR: `brew install tesseract` (Mac) or [download](https://github.com/UB-Mannheim/tesseract/wiki) (Windows)
  - Poppler: `brew install poppler` (Mac) or [download](https://github.com/oschwartz10612/poppler-windows/releases) (Windows)

### Installation

1. **Clone the repository:**
```bash
git clone https://github.com/Shauryacious/ResXcan.git
cd ReXcan
```

2. **Install Python dependencies:**
```bash
cd python
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

3. **Install Node.js dependencies:**
```bash
# Server dependencies
cd ../server
npm install

# Client dependencies
cd ../client
npm install
```

4. **Configure environment variables:**
```bash
# Python: Copy .env.template to .env and add LLM API keys
cd python
cp .env.template .env
# Edit .env and add at least one LLM API key (Groq recommended)

# Server: Copy .env.example to .env
cd ../server
cp .env.example .env
# Edit .env with MongoDB URI, JWT secret, etc.
```

### Running the Application

**Option 1: Use the start script (recommended)**
```bash
chmod +x start-all.sh
./start-all.sh
```

**Option 2: Start services manually (one by one)**

Open **4 separate terminal windows** and run the following commands:

#### Terminal 1: Python FastAPI Server (Port 8000)
```bash
cd python
source venv/bin/activate  # On Windows: venv\Scripts\activate
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

#### Terminal 2: Node.js Express Server (Port 3000)
```bash
cd server
npm run dev
```

#### Terminal 3: Document Processing Workers
```bash
cd server
npm run worker:dev
```

#### Terminal 4: React Frontend (Port 5173)
```bash
cd client
npm run dev
```

**Note:** Make sure MongoDB and Redis are running before starting the services:
```bash
# Start MongoDB (Mac)
brew services start mongodb-community

# Start Redis (Mac)
brew services start redis
```

### Service URLs

- **Python API**: http://localhost:8000
- **Node.js API**: http://localhost:3000
- **Frontend**: http://localhost:5173

### Verify Installation

1. Check Python API health:
```bash
curl http://localhost:8000/health
```

2. Check Node.js API health:
```bash
curl http://localhost:3000/health
```

3. Open frontend in browser: http://localhost:5173

---

## ğŸ“Š Key Features

### Core Capabilities

- âœ… **Multi-format Support**: PDFs (text & scanned), images (PNG, JPG, JPEG, GIF, BMP, TIFF, WEBP)
- âœ… **Intelligent OCR**: Multi-layer fallback (pdfplumber â†’ EasyOCR â†’ Tesseract â†’ Cloud OCR)
- âœ… **Field Extraction**: 8 core fields + line items with high accuracy
- âœ… **Confidence Scoring**: Per-field confidence with auto-accept/flag thresholds
- âœ… **LLM Fallback**: Surgical LLM calls only for low-confidence fields (<20% of cases)
- âœ… **Canonicalization**: Standardized dates, currencies, vendor names
- âœ… **Duplicate Detection**: Exact and near-duplicate invoice detection
- âœ… **Human-in-the-Loop**: Review queue for flagged invoices
- âœ… **Audit Trail**: Complete logging of all corrections
- âœ… **Export**: JSON & CSV export with ERP-specific formats
- âœ… **Learning System**: Captures patterns from manual corrections

### Performance Metrics

- **Processing Speed**: 5-20 seconds per invoice
- **Accuracy**: 88% average (validation dataset)
- **Auto-accept Rate**: ~70% of fields (confidence â‰¥0.85)
- **LLM Usage**: <20% of fields require LLM fallback
- **Cache Hit Rate**: High (OCR & LLM responses cached)

---

## ğŸ”§ API Endpoints

### Python FastAPI (Port 8000)

- `GET /health` - Health check
- `POST /upload` - Upload invoice file
- `POST /ocr?jobId=<id>` - Run OCR extraction only
- `POST /process?jobId=<id>` - Run full processing pipeline
- `POST /verify` - Apply manual corrections
- `GET /export/csv?jobId=<id>` - Export as CSV
- `GET /export/json?jobId=<id>` - Export as JSON
- `GET /metrics` - System metrics
- `GET /review/queue` - Get flagged invoices
- `POST /review/{id}/apply` - Apply corrections
- `GET /audit/{jobId}` - Get audit trail

### Node.js Express (Port 3000)

- `GET /api/v1/health` - Health check
- `POST /api/v1/invoices/process` - Process invoice
- `GET /api/v1/invoices/review/queue` - Review queue
- `GET /api/v1/invoices/metrics` - Metrics
- `GET /api/v1/invoices/export/csv` - CSV export
- `POST /api/v1/auth/register` - User registration
- `POST /api/v1/auth/login` - User login

---

## ğŸ§ª Testing

```bash
# Python tests
cd python
pytest tests/

# Run full pipeline test
python test_full_pipeline.py

# Node.js tests
cd server
npm test
```

---

## ğŸ“š Documentation

- [Problem Statement](./documentation/PROBLEM_STATEMENT.md)
- [Implementation Summary](./documentation/IMPLEMENTATION_SUMMARY.md)
- [Features List](./documentation/FEATURES_LIST.md)
- [Quick Start Guide](./documentation/QUICK_START.md)
- [Python Architecture](./python/ARCHITECTURE.md)
- [Server README](./server/README.md)

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

[Add your license here]

---

## ğŸ™ Acknowledgments

- Built with FastAPI, Express.js, React, and modern AI/ML technologies
- OCR powered by EasyOCR, Tesseract, and Google Cloud Document AI
- LLM support from Groq, Google Gemini, OpenAI, and Anthropic

---

**Status**: âœ… **PRODUCTION READY**

*Last Updated: November 2025*
